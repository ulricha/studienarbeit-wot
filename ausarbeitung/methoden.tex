%% methoden.tex

\chapter{Methoden und Materialien}
\label{ch:Methoden}
%% ==============================

%% ==============================
\section{Warum eigene Software?}
%% ==============================
\label{ch:Grundlagen:sec:WarumEigene}
Das bereits in Abschnitt \ref{ch:Grundlagen:sec:RelatedWork} erwähnte
\emph{wotsap}-Projekt berechnet täglich die Struktur des Web of
Trust. Die Daten werden für eine Web-Applikation benutzt, die
grundlegende Statistiken über Schlüssel berechnet und Pfade zwischen
Schlüsseln graphisch darstellt. Zusätzlich werden die Daten aber auch
für weitere Analysen zur Verfügung gestellt. In diesem Abschnitt wird
begründet, warum für die vorliegende Arbeit nicht auf diese Daten
zurückgegriffen wurde, sondern die Datenextraktion selbst vorgenommen
wurde.

Ein Ziel dieser Arbeit ist es, die Struktur des Web of Trust abseits
der grössten starken Zusammenhangskomponente zu
untersuchen. \emph{wotsap} berechnet allerdings nur die Struktur eben
dieser Zusammenhangskomponente. Schlüssel, die nicht in dieser
Komponente enthalten sind, werden nicht beachtet. \emph{wotsap}
beginnt bei mehreren sehr gut vernetzten Schlüsseln, die sicher in der
MSCC liegen. Von diesen ausgehend werden die Signaturen in der Art
einer Breitensuche (rückwärts) verfolgt. Aufgrund dieser Methode
scheint es mit vertretbarem Aufwand nicht möglich, die Extraktion auf
alle Schlüssel auszudehnen.

Der Anwendungszweck der \emph{wotsap}-Daten ist ausschliesslich die
strukturelle Analyses des Netzes. Die über die reine Struktur
hinausgehenden Daten, die über Schlüssel und Signaturen gespeichert
werden, sind dabei auf ein Minimum reduziert: Für Schlüssel werden
ausschliesslich die KeyID und die primäre UserID gespeichert, für
Signaturen der Cert level und die Schlüssel. Diese Reduktion erlaubt
zwar eine sehr kompakte Speicherung der Daten, macht es aber für eine
Auswertung weiterer Eigenschaften von Schlüsseln und Signaturen
unbrauchbar. Das verwendete Dateiformat ist ausserdem recht unflexibel
und lässt eine Speicherung weiterer Daten nur mit grösserem Aufwand
zu.

Die \emph{wotsap}-Daten beinhalten nur die zum jeweiligen Zeitpunkt
gültigen Schlüssel und Signaturen. Dieser "`Schnappschuss"' reicht für
die strukturelle Analyse des Graphen aus. Zeitliche Entwicklungen,
beispielsweise die Grösse des Datenbestandes, die Verwendung
bestimmter Verschlüsselungs- und Signaturalgorithmen und die Entwicklung
einzelner Komponenten können damit aber nicht nachvollzogen werden.

Die \emph{wotsap}-Methode liefert also nicht die im Rahmen dieser
Arbeit benötigten Daten. Eine Anpassung der Software würde auf eine
komplette Neuimplementierung hinauslaufen. Ausserdem beruht die
Extraktion der Daten bei \emph{wotsap} auf der veralteten und kaum
mehr benutzten \emph{PKS}-Keyserver-Implementierung (siehe Abschnitt
\ref{ch:Grundlagen:sec:Design:subsec:der-sks-keyserver}).

Darüber hinaus ist allerdings der \emph{wotsap}-Datensatz
fehlerhaft. Diese Fehler werden sowohl durch Fehler in der
Implementierung als auch durch einen fehlerhaften Datenbestand auf dem
verwendeten Keyserver verursacht: Die grösste starke
Zusammenhangskomponente die durch XXX berechnet %FIXME
wurde (MSCC-1), enthält mit dem Stand vom 02.12.2009 ca. 45100
Schlüssel, während der \emph{wotsap}-Datensatz (MSCC-2) vom gleichen
Tag nur ca. 42130 Schlüssel enthält. Diep Differenz zwischen den
Datensätzen ergibt einerseits, dass ca. 1000 Schlüssel in MSCC-1
fehlen, die in MSCC-2 vorhanden sind. Eine stichprobenartige Analyse
von 20 Schlüsseln zeigt, dass diese Schlüssel überwiegend durch
Signaturketten an die MSCC angebunden sind, die aufgrund von
widerrufenen Schlüsseln oder Schlüsselteilen unterbrochen sind. Dabei
treten u.a. Signaturen auf komplett widerrufenen Schlüsseln und
Signaturen auf widerrufenen UserIDs auf. \emph{wotsap} benutzt GnuPG,
um die OpenPGP-Pakete eines Schlüssels zu parsen. Der Code zum Parsen
der GnuPG-Ausgabe ist fehlerhaft und führt dazu, dass \emph{wotsap}
Widerrufssignaturen fäschlicherweise nicht beachtet.

Auf der anderen Seite sind ca. 3980 Schlüssel zwar in MSCC-1
vorhanden, nicht aber in MSCC-2. Um den Grund dafür zu finden, wurde
für 10 zufällig ausgewählte Schlüssel aus dieser Menge eine
Signaturkette (d.h. ein Pfad) zu einem Schlüssel gesucht, der sowohl
in MSCC-1 als auch in MSCC-2 vorhanden ist. Ebenfalls wurde eine Kette
in der anderen Richtung gesucht. Die Signaturen dieser Ketten wurden
mittels GnuPG kryptographisch verifiziert, um sicherzustellen, dass
sie gültig sind. Kann für beide Richtungen jeweils eine Kette
erfolgreich verifiziert werden, so ist der betreffende Schlüssel per
definitionem in der MSCC. Im vorliegenden Fall konnte das für alle
Schlüssel der Stichprobe gezeigt werden. Der Fehler liegt also
wiederrum bei \emph{wotsap}, dass diese Schlüssel fälschlicherweise
ausschliesst. Als Ursache dafür ergab sich in allen betrachteten
Fällen der fehlerhafte Bestand des Keyservers
\emph{wwwkeys.ch.pgp.net}, der von \emph{wotsap} verwendet wird. Die
Schlüssel wurden von \emph{wotsap} nicht in die MSCC-2 übernommen,
weil Teile der dazu notwendigen Signaturketten (komplette Schlüssel
oder einzelne Signaturen) auf dem Keyserver nicht vorhanden
sind. Diese fehlenden Teile sind aber auf allen Keyservern des
\emph{SKS}-Verbundes %FIXME
vorhanden. Da die Ursache in allen untersuchten F\"allen die gleiche
war, kann angenommen werden, dass der Fehler systematisch ist und
diesen Teil der Diskrepanz zwischen den Datens\"atzen vollst\"andig
erkl\"art. Als Ursache kommen eine mangelhafte Synchronisation
zwischen \emph{wwwkeys.ch.pgp.net} und dem \emph{SKS}-Netzwerk sowie
Fehler in der auf \emph{wwwkeys.ch.pgp.net} verwendeten
\emph{PKS}-Version in Frage.

Die Natur der Fehler legt nahe, dass hauptsächlich solche Schlüssel
fehlen bzw. fälschlich einbezogen wurden, die nur über eine sehr
geringe Anzahl von redundanten Pfaden zur bzw. von der MSCC
verfügen. Gäbe es mehr redundante Pfade, so hätten einzelne
fehlerhafte Informationen (fehlende bzw. fäschlicherweise als gültig
betrachtete Schlüssel oder Signaturen) einen geringeren Einfluss.

Die Anzahl fehlender bzw. fälschlich einbezogener Schlüssel (ca. 9\%
fehlend, ca. 2\% fälschlich einbezogen relativ zu MSCC-1) ist so
gross, dass qualitative Fehler in der Graphenstruktur zu erwarten
sind. Insbesondere Aussagen über die Verteilung von Knotengraden und
ähnliche Aussagen anhand dieser Daten sind mit Vorsicht zu
geniessen. Eine Reihe von Arbeiten verwendet die \emph{wotsap}-Daten
als Beispiel für ein empirisches soziales bzw. Small-World-Netzwerk
\cite{Brondsema2006} \cite{Heikkila2009} \cite{Dell'Amico2007}. Sofern
die Ergebnisse dieser Arbeit auf experimentellen Resultaten aufbauen,
die mit diesen Daten gewonnen wurden, sollten sie daher mit korrekten
Daten überprüft werden. Der Keyserver \emph{wwwkeys.ch.pgp.net} sollte
von Anwendern nicht mehr benutzt werden.

\section{Design und Implementierung}
\label{ch:Grundlagen:sec:Design}

Dieser Abschnitt beschreibt die im Rahmen dieser Arbeit erstellte
Software zur Extraktion und Analyse des Web of Trust. Abschnitt
\ref{ch:Grundlagen:sec:Design:subsec:der-sks-keyserver} beschreibt
zunächst die Keyserver-Software \emph{SKS}, auf die %FIXME
der Extraktionsteil aufbaut. Abschnitt
\ref{ch:Grundlagen:sec:Design:subsec:der-sks-keyserver} beschreibt
dann die entwickelte Software selbst und begründet das Design.

\subsection{Der SKS Keyserver}
\label{ch:Grundlagen:sec:Design:subsec:der-sks-keyserver}

SKS (Synchronizing Key Server) löst die bis dahin verbreitetste
Keyserver-Software PKS (Public Key Server) ab und wird inzwischen auf
so gut wie allen Keyservern benutzt. Mit \emph{pgp.mit.edu} wurde im
Juli 2009 der letzte grosse Keyserver auf SKS umgestellt. PKS benutzt
ein auf E-Mails basierendes Protokoll zur Synchronisation zwischen
Keyservern, das ausgesprochen ineffizient ist. Ausserdem kommt es mit
einigen Bestandteilen des aktuellen OpenPGP-Standards wie
z.B. \emph{PhotoIDs} und mehreren Unterschlüsseln nicht
zurecht. PKS-Keyserver können über ein Webinterface, ein
E-Mail-Interface und das auf HTTP basierende
HKP-Protokoll\footnote{http://tools.ietf.org/html/draft-shaw-openpgp-hkp-00}
abgefragt werden.

Im Unterschied dazu kommunizieren SKS-Keyserver zur Synchronisation
direkt (ohne Umwege über Mailserver) miteinander.  Dazu wird ein
binäres "`Gossip"'-Protokoll benutzt, dass auf einem effizienten
Algorithmus zum Abgleich von Datensätzen beruht
\cite{Minsky2003}. SKS unterstützt alle Bestandteile des
OpenPGP-Standards.

SKS ist in der Sprache Objective Caml (OCaml) implementiert und
benutzt die Datenbank Berkeley DB als Datenablage. Ein
Datenbankeintrag besteht dabei aus einem kompletten OpenPGP-Key,
d.h. einer Reihe von OpenPGP-Paketen. SKS ist in zwei Prozesse
aufgeteilt: der \emph{db}-Prozess beantwortet Datenbank-Abfragen für
die verschiedenen Abfragemöglichkeiten (Webinterface, HKP) während der
\emph{recon}-Prozess für den Abgleich der Datenbank mit anderen
Keyservern zuständig ist.

\subsection{Eigene Software}
\label{ch:Grundlagen:sec:Design:subsec:eigene-software}

Die im Rahmen dieser Arbeit entwickelte Software besteht aus zwei
Teilen: Der Extraktionsteil liesst Schlüssel aus der Datenbank eines
Keyservers aus, parst sie, reduziert sie dabei auf die benötigten
Daten und speichert sie in einer Datei ab. Die reduzierten Daten
werden in einer SQL-Datenbank (PostgreSQL FIXME cite) abgelegt und
können dort abgefragt werden. Der zweite Teil besteht aus einer Reihe
von Werkzeugen zur Analyse dieser Daten entsprechend der Zielsetzung
dieser Arbeit.

\subsubsection{Datenextraktion}
\label{sec:datenextraktion}

Die Extraktion der Daten ist recht zeitaufwendig. Auf der zur
Verfügung stehenden Hardware (FIXME Poolrechner Hardware) werden
ca. XX Stunden benötigt. Durch die Aufteilung kann die Extraktion der
Daten einmalig auf dem Keyserver vorgenommen werden, während die Daten
anschliessend auf beliebigen Rechnern zur Verfügung stehen.

Der Extraktionsteil wurde direkt in die SKS-Software
integriert. Dadurch ergeben sich mehrere Vorteile: 

\begin{itemize}
\item Das Interface von SKS für den Datenbankzugriff kann
  wiederverwendet werden
\item SKS enthält einen rudimentären OpenPGP-Parser, d.h. eine Reihe
  von Funktionen, die die Byte-Struktur einzelner OpenPGP-Pakete sowie
  die Paket-Struktur des Schlüssels parsen und die darin enhaltenen
  Informationen in Datenstrukturen zugänglich machen. Durch die
  Verwendung dieser Funktionen kann auf eine eigene Implementierung
  eines OpenPGP-Parsers verzichtet werden.
\item Die in SKS definierten Datenstrukturen für die Auswertung von
  OpenPGP-Paketen und weitere Hilfsfunktionen, beispielsweise für den
  Umgang mit OpenPGP-Fingerprints, können verwendet und erweitert werden
\end{itemize}

Derzeit läuft der Extraktionsteil in Form eines eigenen Prozesses, der
einmalig den kompletten Datenbestand ausliest. Dieser Teil könnte aber
auch direkt in den \emph{db}-Prozess integriert werden, so dass der
laufende Keyserver konstant neue oder geänderte Schlüssel reduziert
und in der SQL-Datenbank ablegt. Auf diese Weise könnte ein ständig
aktueller Datenbestand ohne den Aufwand des vollständigen Auslesens
realisiert werden. Diese Möglichkeit wurde im Rahmen dieser Arbeit
nicht verfolgt, kann aber mit geringem Aufwand realisiert werden.

Da der Extraktionsprozess nur lesend auf die SKS-Datenbank zugreift,
kann er die Daten auslesen, während die \emph{recon}- und
\emph{db}-Prozesse laufen. Eine Unterbrechung des SKS-Betriebes ist
nicht notwendig.

Als Sprache für die Implementierung wurde OCaml ausgewählt. Im
Extraktionsteil bestand dafür aufgrund der Integration in SKS keine
Wahl. Der Analyseteil wurde ebenfalls in OCaml implementiert. Da die
dort verwendeten Daten ausschliesslich aus der SQL-Datenbank stammen
und dort nur primitive Datentypen (Strings, Ganz- und
Fliesskommazahlen) gespeichert werden, können aber für diesen Teil
auch problemlos andere Sprachen verwendet werden.

Der Extraktionsteil iteriert über alle in der SKS-Datenbank
enthaltenen Schlüssel. Jeder Schlüssel wird durch die in SKS
enthaltenen Funktionen geparst. Der Extraktionsteil FIXME muss dann
noch
\begin{itemize}
\item Entscheiden, ob der Schlüssel zurückgezogen oder abgelaufen
  ist. Dazu werden die Selbstsignaturen auf den einzelnen UserIDs
  betrachtet. Falls zu einer UserID mehrere Selbstsignaturen
  vorliegen, wird entsprechend der Empfehlung im OpenPGP-Standard nur
  die aktuellste verwendet. Liegt ein Rückrufzertifikat vor oder ist
  der Schlüssel abgelaufen, wird das Ablauf- bzw. Rückzugsdatum
  gespeichert.
\item Fremdsignaturen sammeln. Dazu wird jede UserID betrachtet und
  die darauf angebrachten Signaturen ohne Duplikate gespeichert. Hier
  wird ebenfalls nur die neueste Signatur verwendet. Handelt es sich
  bei der neuesten Signatur um eine Rückrufsignatur, wird das Datum
  des Rückrufs gespeichert und zusätzlich die nächstältere Signatur
  gesucht, auf die sich der Rückruf bezieht.
\item Den Schlüssel und jede Fremdsignatur auf die benötigten Daten
  reduzieren. Für den Schlüssel sind dies (falls vorhanden) Rückzugs-
  und Ablaufdatum, die KeyID, die Liste aller UserIDs und die
  Information, welche davon die primäre UserID ist, das
  Erstellungsdatum des Schlüssels und der verwendete
  Public-Key-Algorithmus sowie dessen Schlüssellänge.

  Eine Fremdsignatur wird reduziert auf die KeyID des Unterzeichners
  FIXME, den Zertifizierungslevel, das Erstellungsdatum der Signatur,
  falls vorhanden Ablauf- und Rückzugsdatum, der verwendete
  Signaturalgorithmus und der verwendete Public-Key-Algorithmus.
\end{itemize}

Grundsätzlich werden Schlüssel nur dann verworfen, wenn sie nicht
parsebar, d.h. keine Abfolge gültiger OpenPGP-Pakete sind. Schlüssel,
die zurückgezogen oder abgelaufen sind, werden unter Angabe des
jeweiligen Datums trotzdem gespeichert. Auf diese Weise ist
sichergestellt, dass der Datensatz möglichst vollständig ist. Für
einen beliebigen Zeitpunkt stehen alle dann gültigen Schlüssel und
Signaturen zur Verfügung. Es kann also gewissermassen ein
"`Snapshot"' des Web of Trust zu einem beliebigen Zeitpunkt
analysiert werden.

Sind alle Schlüssel extrahiert, werden noch solche Signaturen
entfernt, deren erstellender Schlüssel im Datenbestand nicht vorhanden
ist. Ausserdem werden für Signaturen, die von einem Unterschlüssel
erstellt wurden, die KeyID des signierenden Schlüssels auf die des
"`Oberschlüssels"' geändert. Dies ist notwendig, weil das hier
verwendete Datenmodell keine Informationen über Unterschlüssel
enthält.

Erwähnt werden muss, dass der Parse-Vorgang nur prüft, ob die
Paketfolge eines Schlüssels dem OpenPGP-Standard entspricht. Es wird
keinerlei kryptographische Verifizierung der Selbst- und
Fremdsignaturen eines Schlüssels vorgenommen. Grundsätzlich können
ohne Probleme Signaturpakete auf einem Schlüssel angebracht und diese
auf einem Keyserver veröffentlicht werden, auch wenn der Ersteller
nicht über das private Schlüsselmaterial für die kryptographische
Signatur verfügt. Keyserver verifizieren keine Signaturen, so dass der
Signaturteil des Pakets mit beliebigem Inhalt gefüllt werden
kann. GnuPG und PGP verifizieren natürlich Signaturen, so dass eine
solches Signaturpaket dort nicht verwendet wird und damit kein
wirkliches Angriffspotential bietet. Eine Möglichkeit für den
Extraktionsteil bestünde darin, die Signaturen jedes
OpenPGP-Schlüssels mit GnuPG verifizieren zu lassen. Dagegen sprechen
zwei Gründe: Einerseits wäre der Aufruf von GnuPG sehr
zeitaufwendig. Für jeden Schlüssel müssten der Schlüssel in einen
GnuPG-Schlüsselring eingefügt werden. Zusätzlich müssten noch alle
Schlüssel, die den jeweiligen Schlüssel signiert haben, einzeln in der
SKS-Datenbank gesucht und in den Schlüsselring eingefügt werden, um
die Signaturen verifizieren zu können. Letztendlich kostet der Aufruf
von GnuPG selbst Zeit. Für die Anzahl der hier verarbeiteten Schlüssel
(2,6 Millionen) scheint dieser Ansatz daher ungeeignet. Sicherlich
sind Schlüssel mit defekten Signaturpaketen auf den Keyservern
vorhanden. Allerdings müsste deren Anzahl sehr gross sein, um
signifikante Änderungen in der Struktur des Graphen und den
statistischen Auswertungen der Schlüsseleigenschaften zu
erreichen. Eine grosse Zahl solcher Pakete scheint aber
unwahrscheinlich, da zumindest unter Sicherheitsaspekten ein Angreifer
damit keinen offensichtlichen Gewinn erreichen kann.

Die so extrahierten Daten werden auf einem beliebigen Recher in einer
SQL-Datenbank (PostgresQL) abgelegt. Auf diese Weise kann darauf
verzichtet werden, eigene Selektionsmechanismen zu
implementieren. Stattdessen kann die gewünschte Datenmenge einfach als
SQL-Abfrage formuliert werden. Auf diese Weise ergibt sich eine
deutlich flexiblere Abfragemöglichkeit. Die Ablage in der Datenbank
ist zwar etwas langsamer als die Daten im Speicher zu
halten. Andererseits müssen die Daten aber nicht jedesmal komplett in
den Speicher geladen und dort gehalten werden. Ausserdem werden
effiziente Indexstrukturen der Datenbank genutzt und müssen nicht
selbst implementiert werden.

Die Tabellen sind wie folgt strukturiert: TODO

Die Zuordnung einzelner Schlüssel zu ihren starken
Zusammenhangskomponenten erfolgt über die Tabelle
\emph{component\_ids}. Diese wird erst in einem separaten Schritt
befüllt, nachdem die Komponentenstruktur berechnet wurde.

\begin{figure}[h]
\centering
{\footnotesize
\begin{lstlisting}[language=SQL]
(SELECT signer, signee
   FROM sigs INNER JOIN keys on sigs.signer = keys.keyid 
   WHERE 
     (keys.revoktime IS NULL OR keys.revoktime > $timestamp) 
     AND (keys.exptime IS NULL OR keys.exptime > $timestamp)
     AND (sigs.revoktime IS NULL OR sigs.revoktime > $timestamp) 
     AND (sigs.exptime IS NULL OR sigs.exptime > $timestamp)) 
INTERSECT 
(SELECT signer, signee 
   FROM sigs INNER JOIN keys on sigs.signee = keys.keyid
   WHERE 
   (keys.revoktime IS NULL OR keys.revoktime > $timestamp) 
   AND (keys.exptime IS NULL OR keys.exptime > $timestamp) 
   AND (sigs.revoktime IS NULL OR sigs.revoktime > $timestamp) 
   AND (sigs.exptime IS NULL OR sigs.exptime > $timestamp))"
\end{lstlisting}
}
\caption{Abfrage aller zum Zeitpunkt \$timestamp gültigen Signaturen}
  \label{fig:all-valid-keys}
\end{figure}

Als Beispiel gibt Abb. \ref{fig:all-valid-keys} ein SQL-Statement an,
mit dem alle gültigen (d.h. nicht zurückgezogenen oder abgelaufenen)
Signaturen zu einem bestimmten Zeitpunkt abgerufen werden können.

Wie beschrieben wird in einem Durchlauf der gesamte Datenbestand
extrahiert. Aufgrund der Integration in SKS wäre es auch problemlos
möglich, den Extraktionsteil nicht als eigenständigen Prozess zu
implementieren, sondern den \emph{db}-Prozess entsprechend zu
erweitern, so dass jeder neue oder geänderte Schlüssel direkt in der
SQL-Datenbank abgelegt wird. Auf diese Weise könnte ein jederzeit
aktueller Datenbestand erhalten werden, ohne dass er ständig komplett
neu berechnet werden muss.

\subsubsection{Datenauswertung}
\label{sec:datenauswertung}

Der Teil zur Datenauswertung besteht aus einer Reihe von unabhängigen
Werkzeugen, die die jeweiligen Analyseaufgaben implementieren. Diese
sind als Kommandozeilenprogramme in eigenen Prozessen realisiert. Die
Aufgaben der einzelnen Werkzeuge sind in Tab. \ref{tab:tools}
aufgeführt.

\begin{table}

  \begin{tabular}[h]{|l|p{9cm}|}
    \hline
    basic-properties-mpi & Verteilung von Eingangs- und Ausgangsgraden,
    Komponentengrössen, Nachbarschaften, Durchmesser, Radius,
    durschnittliche Pfadlängen (parallelisiert mittels
    MPI\\
    \hline
    betweeness-mpi & Berechnung der Betweeness-Zentralität
    (parallelisiert mittels MPI) \\
    \hline
    clustering-coefficient-mpi & Berechnung des Clustering Coefficient
    (parallelisiert mittels MPI) \\
    \hline
    export & Export des Graphen in verschiedene Dateiformate (igraph,
    Cytoscape) \\
    \hline
    meta-graph & Zeichnung der Struktur der starken
    Zusammenhangskomponenten \\
    \hline
    db-scc-information & Befüllt die SQL-Datenbank mit der Zuordnung
    von Knoten zu Zusammenhangskomponenten \\
    \hline
    dump-sql & Legt die extrahierten Daten einmalig in der
    SQL-Datenbank ab \\
    \hline 
    investigate-component & Untersucht einzelne
    Zusammenhangskomponente in Bezug auf Herkunft der UserIDs
    (Domains) und den Zeitraum der Entstehung der Signaturen \\
    \hline
    mscc-size & Entwicklung der Schlüsselanzahl der grössten starken
    Zusammenhangskomponente \\
    \hline
    simple-stats & Statistiken über die Verwendung bestimmter
    Schlüsseleigenschaften (Algorithmen, Schlüssellängen usw.) \\
    time & Entwicklung der Verwendung von Signatur- und
    Public-Key-Algorithmen und deren Schlüssellängen\\
    \hline
  \end{tabular}
  \caption{Foobar}
  \label{tab:tools}
\end{table}

\section{Community-Analyse}
\label{sec:community-analyse}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "diplarb"
%%% End: 
