* Studienarbeit Web of Trust
** Abstract
** Einleitung
*** Allgemeines Blabla
*** Zielsetzung (aus Exposee, bzw. alles rein was tatsächlich gemacht wurde)
**** Software zur Erstellung der Datenbasis und Analyse derselben -> Grundlage für weitere Arbeiten
**** Herausfinden: wie stark wird das WoT benutzt (aus Graph), von wem wird das WoT benutzt
**** Allgemein: Strukturelle Untersuchung des gesamten Graphen. 
**** Vergleich mit Arbeiten, die ältere oder unvollständigere Daten benutzt haben.
**** Grösse der MSCC in Relation zu Gesamtzahl der Knoten sehr klein: Wie ist der Rest strukturiert? -> "unerforschte Bereiche" der MSCC
**** Communities
***** Small-World/Scale-Free/Clustering Coefficient deutet auf modulare Struktur hin. 
***** Lässt sich mit vorhandenen Algorithmen und akzetablem Aufwand die MSCC in eine Community-Struktur zerlegen?
***** Lassen sich die erhaltenen Communities sinnvoll zuordnen? (Soziale Gruppen/KSPs) -> Lassen sich Schlüsse ziehen, wie das Netz zustande kommt?
**** Statistiken: Verwendung von Algorithmen und Schlüssellängen, best. Features (Cert level), zeitliche Entwicklung...
***** Warum ist das relevant: ernsthafte Angriffe gegen RSA mit kurzen Schlüssellängen (<= 1024 bit,  siehe Paper über 768-bit Faktorisiriung), ernsthafte Angriffe gegen MD5 (total am Arsch) und SHA1 (schwer gebeutelt)
**** Abgrenzung: Arbeit hat nichts mit der zugrundeliegenden Kryptographie im eigtl. Sinne zu tun, beschäftigt sich mit sozialen Aspekten (?) und der tatsächlichen Verwendung.
*** Gliederung
** Grundlagen und Theorie
*** Kryptographie mit öffentlichen Schlüsseln
**** Funktionsprinzip
**** Authentisierung von Schlüsseln
***** Grundproblem
***** Zentrale PKI
***** Web of Trust
*** PGP/GnuPG
**** Geschichte von PGP/PGP.com und GnuPG
**** Eigenschaften/Fähigkeiten der Implementierungen allgemein
**** Trust-Modell beschreiben (ausführlich)
**** Was drückt eine Signatur aus?
**** Die soziale Komponente
***** Wie kommen grundsätzlich Zertifizierungen zustande?
****** Keysigning-Parties
****** Face-to-face
***** Gruppen, die bekanntermassen stark auf das WoT bauen
****** Debian
****** andere Distributionen?

*** Der OpenPGP-Standard
**** Paketformat v4
**** Unterschiede v3
*** Keyserver-Netzwerk
**** Prinzip: Öffentliche Keyserver (auch private denkbar) stellen OpenPGP-Keys für PGP-Benutzer bereit
**** Web of Trust kann natürlich auch ohne Keyserver betrieben werden, Veröffentlichung ist nicht notwendig. Dann aber privat, keine öffentliche Infrastruktur.
**** Keyserver gleichen ihren Datenbestand untereinander ab
**** Beim WoT (Signaturen...) macht der Keyserver die gesamte Vernetzungsstruktur öffentlich. Das bedeutet ein Privacy-Problem (Signaturen sind Abbild von soz. Beziehungen/Vertrauen), das wahrscheinlich (Beleg?) vielen Benutzern nicht bewusst ist. D.h. Keyserver stellen das soziale Netzwerk zur Verfügung.
**** Das öffentliche PGP-Netzwerk
***** Struktur und Grösse
***** Wichtiges Grundprinzip: Was dort ist bleibt. Vorteile und Nachteile...
****** Warum gut? Warum schlecht? (WP)
**** Andere Ansätze: PGP Global Directory
*** Graphentheorie allgemein
*** Netzwerkanalyse
**** Netzwerkstatistiken
***** Clustering coefficient
***** Betweeness Centrality
**** Netzwerkmodelle: Random, Small World, Scale free, Implikationen
**** Communities - Definition, Algorithmen
** Related Work
*** Web of Trust im Allgemeinen
**** Analyse von WoT-Communities: Duch2005, Boguna2004
**** Wotsap + Webseiten (
**** Netzwerkstatistiken: Capkun2002
*** Analyse von Netzwerken allgemein
*** Analyse von Community-Strukturen
** Methoden und Materialien -> Beschreibung der Software, der Datenextraktion etc.
*** Warum eigene Extraktion? Warum nicht die wotsap-Daten benutzt?
**** Untersuchung der Struktur abseits der MSCC
**** Komplette Geschichte liegt vor, Zustand zu einem beliebigen Zeitpunkt -> Statistiken, kann strukturelle Entwicklung nachvollziehen
**** Vollständigere Informationen über Schlüssel und Signaturen
**** wotsap läuft auf veraltetem PKS -> wird nirgends benutzt, nicht gewartete Software...
**** Wotsap nicht korrekt
***** Wodurch Fehler verursacht
***** Unterschiede zwischen Datensätzen

*** Design
**** SKS Software
***** Löst veraltetes PKS ab
****** Austausch über Emails
****** Probleme mit OpenPGP-Features: Welche? (Subkeys? KeyIDs?...)
***** Hat PKS fast vollständig abgelöst (alle wichtigen Keyserver umgestellt)
***** Geschrieben in Ocaml
***** Design: Zwei Prozesse (db und recon)
***** DB: Berkeley-Datenbank
***** Algorithmus zum Abgleich der Datenbanken (Set reconciliation) kurz anreissen

**** eigene Software - Methode
***** Extraktion
****** Extraktionsteil ist Patch gegen SKS -> ebenfalls in Ocaml
****** Integration in SKS: erlaubt direkten Zugriff auf Datenbank, Zugriff auf OpenPGP-Low-level-parsing -> muss nur High-level (Paketstruktur, OpenPGP-Semantik) rudimentär selbst entwickeln.
****** Extraktion kann auf laufenden Keyserver zugreifen, da nur lesend. (-> db und recon können laufen)
****** Iteration über Datenbank, Reduzierung auf interessante Daten (Welche?), Speicherung in sexp (einfach)
****** Nur Parsen der Paketstruktur, keine kryptographische Verifizierung.
******* Problem: Jeder kann Signatur-Pakete auf fremden Schlüsseln anbringen, auch wenn die Signatur nicht gültig ist. (Keyserver verifizieren nicht...)
******* Alternative: Jeden Key in GnuPG werfen (nicht nur parsen sondern verifizieren!): dauert zu lange (siehe Wotsap, wobei Hardware unbekannt)
******* Argumentieren, warum das kein Problem ist: Es interessiert die Struktur und Statistik, nicht einzelne Schlüssel. Es sind sicherlich kaputte/falsche Signaturen vorhanden. Es müssen aber schon ziemlich viele sein, um die Struktur wirklich zu stören/verändern. Das ist wiederum unwahrscheinlich. Ist auch unrealistisches Angriffsszenario, da Signaturen für die Trustberechnung ja kryptographisch verifiziert werden.
****** Grundsatz: Keys nur dann komplett wegwerfen, wenn es gar nicht anders geht (z.B. Public-Key-Packet nicht parsebar, semantisch unsinnig (Beispiel?)). Dadurch möglichst vollständiger Datensatz vorhanden. Der für diese Arbeit interessante Teil davon (valide Keys, Graph) kann durch SQL etc gewonnen werden -> Flexibilität.
******* keine Selbstsignatur (auch keine, die expired/revoked sind)
******* nicht parsebar -> kaputte Pakete
****** Speicherung in SQL-DB, vielfältige Abfragemöglichkeiten (muss keine eigene Abfragemöglichkeit von Hand schreiben, Ausnutzung von Indizes etc)
******* muss die Daten nicht jedesmal neu aus sexp-Datei laden, muss die Daten nicht komplett im Speicher halten
******* Tabellenstruktur
******* Komponentenzuordnung wird in extra Schritt berechnet.
****** Trennung von Extraktion und DB: Sinnvoll, weil Extraktion zeitaufwendig und nur einmal (reicht für diese Arbeit aus)
****** Könnte genauso neue Daten live in Datenbank kippen -> Service, der immer die aktuellen Daten anbietet

****** Ausblick: Weiterentwicklung zu "Messdatenservice" und automatische Generierung von Analysen
***** Analyse
****** Sammlung von kleinen Tools, die die verschiedenen Teile der Aufgabenstellung in Bezug auf Analyse realisieren
****** mehrere unabhängige Commandline-tools, eigene Prozesse
****** greifen teilweise auf Datenbank zu
****** oder nur auf Graphenstruktur in extra Datei
****** Warum eigene Analyse? Warum nicht auf igraph etc zurückgegriffen? Gute Frage...
****** MPI
******* Warum: Graph zu gross, Algorithmen zu komplex...
******* Methode: Abwandlungen von BFS...
******* Distance_statistics trivial
******* Betweeness nach Brandes
** Ergebnisse
*** Kennzahlen Graph insgesamt
**** Wie viele Knoten, Kanten, etc.
*** Komponentenstruktur insgesamt
**** Zahl der Komponenten, Grössenverteilung (scale-free?)
**** Struktur der Komponenten -> wie sind diese untereinander vernetzt (Aggregatkanten...)
**** Zeichung der Struktur (bessere Zeichnung als bisher)
*** Kleine Komponenten (einige wenige herausgreifen + Gesamtbild)
**** Interne Struktur (Grade, Pfadlängen etc)
**** Zusammensetzung der Keys
***** Einteilung der Komponenten nach Nation, Institution, Zeit
***** Aktivität? Ist die Komponente über die Zeit entstanden oder auf einmal (KSP) (Ad-Hoc-Mass)

*** MSCC
**** Netzwerkstatistiken
***** Gradverteilung in/out
***** Zwischen ziemlich wenigen Keys gibt es gegenseitige Signaturen
***** Andere Eigenschaften: (durschnittliche Pfadlängen, Durchmesser, Radius, Eccentricity)
***** (Fehlt noch, trivial): MSD -> Mean significant distance
***** Fragestellung: Small-World? Scale-free?
****** Auch wenn die Gradverteilung nicht scale-free im strikten Sinn ist, hat sie doch wahrscheinlich qualitativ die Eigenschaften, die davon erwartet werden

*** Was anfangen mit Betweeness Centrality? Ist zwar ein hübsches Werkzeug, trägt aber nichts zur Fragestellung bei (?)

*** Communities
**** Liefern Algorithmen erkennbar sinnvolle Einteilung?
**** (falls ich dazu komme) Vergleich von directed und undirected: Motivation s.o.
**** lassen sich soziale Gruppen und KSPs unterscheiden?
**** Community-Struktur zeichnen
**** Interne Struktur der Communities
**** Vergleich mit Komponentenstruktur?
**** Komponenten sind letztendlich auch Communities, d.h. insgesamt Community-Analyse mit zwei Methoden

*** Statistiken
**** Verwendung von Algorithmen (Pubkey und Sig)
**** Zeitliche Entwicklung
***** Zeitliche Interpretation (Einführung von GnuPG, Änderung von Algorithmen-Defaults, SHA1-Problem...)
***** Wie entwickelt sich das Wachstum? Stagniert die Grössenentwicklung?
***** Wie ist das Alter der im Moment aktiven Schlüssel verteilt?
**** Verwendung von Cert levels
** Diskussion
*** Komponentenstruktur
**** SCCs sind auch Communities, die nicht vernetzt sind.
*** MSCC ist die einzige Komponente, die ein aktives WoT mit globalem Anspruch(!) darstellt
*** kleinere Komponenten sind (zumindest wenn sie aus einer KSP stammen) wahrscheinlich inaktiv (?)
*** Geringe Grösse der MSCC in Relation zur Gesamtzahl der Schlüssel und zum Internet
*** überwiegender Teil der PGP-Benutzer legt keinen Wert auf Authentication (oder macht das privat, ist aber unwahrscheinlich)
*** Aus Gradverteilung: Selbst in der MSCC ist die grosse Mehrzahl (Grad 1, 2) kaum angebunden, dadurch kaum Chance auf redundante Trust-Pfade, kaum Robustheit
*** Vergleich mit Literatur: Andere WoT-Analysen: Capkun etc.
*** Vergleich mit Literatur: Social Networks

*** Communities: Auflösungslimit
*** Communities: (falls nicht gemacht) eigentlich wären Overlapping Communities sinnvoll
*** Communities: Vergleich mit Literatur, insb. Paper zu WoT-Communities

*** Falls begründbar: WoT stellt ein Abbild sozialer Beziehungen dar und damit ein Tool für Traffic Analysis (Überwacher kann Punkte/Personen bestimmen, an denen weitere Überwachungsmassnahmen ansetzen können). Aus den Daten lassen sich ohne zusätzliche Informationen Erkenntnisse gewinnen, die einiges über Einzelpersonen und Projekte aussagen. Damit ergibt sich ein Privacy-Problem. Ist das den Leuten bewusst? Gibt es Alternativen, die ohne komplette Offenlegung der Beziehungen funktionieren?
*** Letzter Punkt muss abgeschwächt werden: Relevant ist der Mechanismus, mit dem Signaturen erzeugt werden: private signings _können_ Informationen preisgeben, KSPs tragen nichts wesentliches bei, weil zwischen den Teilnehmern im Allgemeinen keine Vertrauensbeziehung besteht. (Welcher Mechanismus stellt die Mehrheit dar?)
*** Nochmals abschwächen: Die eigentliche Vertrauensbeziehung im Sinne von introducer trust wird nicht offengelegt.
*** WoT setzt Vertrauensbeziehungen vorraus, löst nicht das Problem vertraulicher Kommunikation mit Personen, zu denen (noch) keine Vertrauensbeziehung besteht.
** Conclusion
*** "Toolbox" (naja) für Extraktion und Analyse von PGP-WoT-Daten
*** Analyseergebnisse
*** Nochmal betonen, dass Erreichbarkeit im WoT noch lange nichts über Trust/Validity aussagt. 
*** Wahrsch. Schlussfolgerung: Nerdspielzeug + ernsthaftes Werkzeug für klar umrissene Communities
*** Spekulation über Ursachen geringer Verwendung: Insgesamt zu komplex? Doku zu schlecht? Werkzeuge zu schlect?
*** Basis für Vergleich mit hierarchischer PKI?

